{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Yao Li\n",
    "# yaoli90@illinois.edu\n",
    "# 2019.10.6\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Importing some packages\n",
    "####   The data is in EDF format and needs a special reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Had to use pip3 install pyedflib in Git-Bash\n",
    "from pyedflib import EdfReader # https://github.com/holgern/pyedflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read and format data\n",
    "#### 1. The data is distributed in several files, each file for one patient. \n",
    "#### 2. The EEG data for each patient contains several channels corresponding to different parts of the brain. Here we are only extracting the 'Cz' channel\n",
    "#### 3. The data is a time-series data i.e, signal over a certain length of time. Every patient's data is not of the same time length (Eg: Patient 1 can have a recording of 3000 s, Patient 2 of 5000 s). Let the length be 'N' seconds.\n",
    "#### 4. The data is sampled at a frequency of 'Fs' i.e. Fs data points in 1 second. So, in total there will be Fs(data points/sec)*N(seconds) = number of data points. \n",
    "#### 5. We need to re-format this data in this way:\n",
    "<img src=\"DataFormatting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # A list 'file_dirs' contains all file names of eeg data.\n",
    "    file_dirs = []\n",
    "    for file_idx in range(52, 80):\n",
    "        file_dirs.append('dataBig/eeg/eeg'+str(file_idx)+'.edf')\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    #for file_dirs[0]:\n",
    "    for file_dir in file_dirs:\n",
    "        with EdfReader(file_dir) as f:\n",
    "            # list all signals (eeg channels)\n",
    "            channels = f.getSignalLabels()\n",
    "            # find the index of Cz channel\n",
    "            for i in range(f.signals_in_file):\n",
    "                if 'Cz' in channels[i]:\n",
    "                    Cz_idx = i\n",
    "            # grab the Cz channel signal\n",
    "            Cz = f.readSignal(Cz_idx)\n",
    "            # grab the sampling frequency\n",
    "            Fs = int(f.getSampleFrequency(Cz_idx)) \n",
    "            # calculate the time length of the data\n",
    "            N = int(np.floor(len(Cz)/Fs))\n",
    "            #print(file_dir,'length: {} sec.'.format(N),'sampling frequency: {} d.p./sec.'.format(Fs),'First to second record of Cz: {} '.format(Cz[0:2]))\n",
    "\n",
    "            ###### Your Code Here (do the reformatting and append all patients' data)\n",
    "            \n",
    "            #For 0 to N-1 for each patient\n",
    "            for i in range(N):\n",
    "                #The first index number is 0+Fs*i. For i=0, start is 0 and end is 256 (exclusive, last record is 255).\n",
    "                #For i=1, start is 256 and end is 512 (exclusive, last record is 511)\n",
    "                start = 0 + (Fs*i)\n",
    "                end = Fs + (Fs*i)\n",
    "                new_row = Cz[start:end]         \n",
    "                data.append(new_row)\n",
    "           #print('Appended all rows for patient ' + file_dir)\n",
    "    \n",
    "    #Make data into a numpy array\n",
    "    data = np.array(data)\n",
    "    #print('Data shape: ' + str(data.shape))\n",
    "    \n",
    "    return data\n",
    "    \n",
    "#load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the expert's labels\n",
    "#### An expert 'A' has marked each 1-s interval with a label of either '0' or '1'. '0' means the expert thinks it is not a seizure, '1' means they think it is a seizure. \n",
    "#### You need to flatten the labels matrix to a single column array and remove all the 'nan' values\n",
    "<img src=\"LabelFormatting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "\n",
    "    file = 'dataBig/label/annotations_2017_A.csv'\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    data_csv = np.genfromtxt(file, delimiter=',')\n",
    "    labels.append(data_csv)\n",
    "    #print(file,'shape: {}'.format(data_csv.shape))\n",
    "    \n",
    "    ##### Your code here #####\n",
    "    \n",
    "    #Make labels, which is a list, into a numpy array\n",
    "    labels = np.array(labels)\n",
    "    #print('New label 3D array shape: ' + str(labels.shape))\n",
    "    \n",
    "    #Flatten the array by getting rid of one of the dimesions- the x dimension\n",
    "    labels = labels[0, :, :]\n",
    "    #print('2D label array shape: ' + str(labels.shape))\n",
    "    \n",
    "    #Flatten the array again by lining up all the patient columns in a one dimensional array: ([1,2],[3,4]) becomes [1, 3, 2, 4]\n",
    "    labels = labels.flatten('F')\n",
    "    #print('1D label array shape: ' + str(labels.shape))\n",
    "    \n",
    "    #Remove the NaNs\n",
    "    labels = labels[np.logical_not(np.isnan(labels))]\n",
    "\n",
    "    #Make newRowNum equal to the new number of records\n",
    "    newRowNum = len(labels)\n",
    "    #print('newRowNum after NaNs gone: ' + str(newRowNum))\n",
    "    \n",
    "    #Reshape labels\n",
    "    labels = labels.reshape(newRowNum, 1)\n",
    "    #print('Labels FINAL shape: ' + str(labels.shape))\n",
    "    \n",
    "    return labels\n",
    "\n",
    "#load_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for balancing the data (seizure vs healthy)\n",
    "#### As you can tell from the labels, most of the labels are 0 and very few are 1. This leads to an unbalanced dataset and the model may become biased.\n",
    "#### Let's choose only part of the dataset so that the number of '0's and '1's are equal.\n",
    "#### Make sure you when you delete some labels, you delete the corresponding rows in the EEG data as well.\n",
    "<img src=\"Data_Labels.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def balance_data(data,label):\n",
    "def balance_data(data, labels):\n",
    "\n",
    "    ###### Your Code Here ######\n",
    "\n",
    "    \n",
    "    #Find out the number of seizure and healthy labels- np.where output is arr of index nums, arr of values, and dtype \n",
    "    seizure_labels = np.where(labels == 1)\n",
    "    healthy_labels = np.where(labels == 0)\n",
    "\n",
    "    num_seizure = len(seizure_labels[1])\n",
    "    num_healthy = len(healthy_labels[1])\n",
    "    \n",
    "    \n",
    "    # Second step, add the 'labels' column to the 'data' as a new column (appending labels)\n",
    "    data = np.append(data, labels, axis=1)\n",
    "\n",
    "        \n",
    "    # Create two subarrays - one for healthy (whose last column = 0) and one for\n",
    "    # seizure (whose last column = 1)\n",
    "    healthy_arr = data[healthy_labels[0]]\n",
    "    seizure_arr = data[seizure_labels[0]]\n",
    "\n",
    "        \n",
    "    # Randomly delete as many rows from the healthy subarray as it takes\n",
    "    # for both arrays to become equal in size\n",
    "\n",
    "    #Shuffle array\n",
    "    np.random.shuffle(healthy_arr)\n",
    "        \n",
    "    #Delete everything but index row del_num = 103983 to make number of healthy rows equal to seizure rows\n",
    "    #healthy_arr.shape[0]-seizure_arr.shape[0] = 103983\n",
    "    healthy_arr = healthy_arr[healthy_arr.shape[0]-seizure_arr.shape[0]:]\n",
    "\n",
    "        \n",
    "    # Join back the two subarrays and separate them into 'data' and 'label'\n",
    "    data = np.concatenate((healthy_arr, seizure_arr), axis=0)\n",
    "    \n",
    "    #Separate new label array\n",
    "    labels = data[:,(data.shape[1]-1)]\n",
    "\n",
    "    #Reshape labels array\n",
    "    labels = labels.reshape(data.shape[0], 1)\n",
    "\n",
    "    #Delete last column from data\n",
    "    data = data[:,0:(data.shape[1]-1)]\n",
    "    \n",
    "        \n",
    "    return data, labels\n",
    "    \n",
    "#data = load_data()\n",
    "#labels = load_labels()\n",
    "#balance_data(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading some machine learning packages and also the EEG-specific package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pyeeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract relevant features from the EEG time-series data (this is all EEG-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All done, no need to write any code here\n",
    "def create_features(data,labels):\n",
    "    Kmax = 5\n",
    "    Tau = 4\n",
    "    DE = 10\n",
    "    Band = np.arange(1,86)\n",
    "    Fs = 173\n",
    "    F = np.zeros((data.shape[0],5))\n",
    "    nan_idx = []\n",
    "    for i in range(data.shape[0]):\n",
    "        mat = data[i][:]\n",
    "        DFA                = pyeeg.dfa(mat)\n",
    "        HFD                = pyeeg.hfd(mat,Kmax)\n",
    "        SVD_Entropy        = pyeeg.svd_entropy(mat,Tau,DE)\n",
    "        Fisher_Information = pyeeg.fisher_info(mat,Tau,DE)\n",
    "        PFD                = pyeeg.pfd(mat)\n",
    "        Spectral_Entropy   = pyeeg.spectral_entropy(mat, Band, Fs, Power_Ratio=None)\n",
    "        F[i,:] = [DFA, HFD, SVD_Entropy, Fisher_Information, PFD]#, Spectral_Entropy]\n",
    "        if np.any(np.isnan(F[i,:])):\n",
    "            nan_idx.append(i)\n",
    "    F = np.delete(F, nan_idx, axis=0)\n",
    "    labels = np.delete(labels, nan_idx)\n",
    "    return F, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the functions to load data, load labels, balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fab Lab\\Dropbox\\Grad School\\Classes\\HT 504 Software Engineering\\Assignment 4\\pyeeg\\fractal_dimension.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "  L.append(numpy.log(numpy.mean(Lk)))\n",
      "C:\\Users\\Fab Lab\\Dropbox\\Grad School\\Classes\\HT 504 Software Engineering\\Assignment 4\\pyeeg\\spectrum.py:62: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Power_Ratio = Power / sum(Power)\n"
     ]
    }
   ],
   "source": [
    "### Your code here #######\n",
    "data = load_data()\n",
    "\n",
    "labels = load_labels()\n",
    "\n",
    "data_new, labels_new = balance_data(data, labels)\n",
    "\n",
    "features, labels = create_features(data_new, labels_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, test data splitting (features is the X, labels is the Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Dataset:\n",
      "X_train: (18900, 5) X_test (6301, 5)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "# Print the size of training and test dataset\n",
    "print('-------------------------------------------------')\n",
    "print('Dataset:')\n",
    "print('X_train:', X_train.shape, 'X_test', X_test.shape)\n",
    "print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using different algorithms (K Nearest Neighbors, SVM, Decision Tree, Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listed below are the four classifiers you can try one-by-one\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"Decision Tree\", \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [KNeighborsClassifier(5),\n",
    "                SVC(gamma=3, C=1),\n",
    "                DecisionTreeClassifier(max_depth=5),\n",
    "                GaussianNB()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of each algorithm with test set (tune hyperparameters to maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6587843199492144, 'Nearest Neighbors']\n",
      "[0.6518013013807332, 'Linear SVM']\n",
      "[0.6935407078241549, 'Decision Tree']\n",
      "[0.6179971433105856, 'Naive Bayes']\n"
     ]
    }
   ],
   "source": [
    "clf_score=[]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # ignore a warning message of sklearn\n",
    "    for name, clf in zip(names, classifiers): # loop through classifiers\n",
    "        clf.fit(X_train, y_train) # train a classifier\n",
    "        score = clf.score(X_test, y_test) # evaluate the accuracy\n",
    "        clf_score.append([score,name])\n",
    "\n",
    "for score in clf_score:\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
