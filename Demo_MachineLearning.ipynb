{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Yao Li\n",
    "# yaoli90@illinois.edu\n",
    "# 2019.10.6\n",
    "#######################################\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pyeeg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "# Dataset from http://epileptologie-bonn.de/cms/front_content.php?idcat=193&lang=3\n",
    "# The dataset is catagrized into 3 classes, i.e. healthy, inter_ictal, and ictal\n",
    "# and stored in 3 different folders. In each folder, there are 100 recorded eeg\n",
    "# data stored in .txt files. Each file corresponding to one training/testing\n",
    "# data.\n",
    "#\n",
    "# healthy:     label: 1, Healthy dataset\n",
    "# inter_ictal: label: 0, Inter-ictal (transition between healthy to seizure)\n",
    "# ictal:       label:-1, Ictal or seizures\n",
    "def load_data():\n",
    "    file_dirs = []\n",
    "    labels = []\n",
    "    categories = {'healthy': 1, 'inter_ictal': 0, 'ictal': -1}\n",
    "    for cat in categories: # loop through all categories\n",
    "        for file in os.listdir('data/' + cat): # loop through all data files\n",
    "            # append all file directories in a list\n",
    "            file_dirs.append('data/'+cat+'/'+file)\n",
    "            labels.append(categories[cat]) # append the corresponding label\n",
    "\n",
    "    data = np.zeros((len(file_dirs),4097))\n",
    "    # Using the file directories list we just created to read data\n",
    "    for i in range(len(file_dirs)):\n",
    "        data[i][:] = np.loadtxt(file_dirs[i]) # load data from file\n",
    "    labels = np.array(labels) # warp as np array\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate features from raw data\n",
    "#\n",
    "# Features:\n",
    "# DFA: Detrended Fluctuation Analysis\n",
    "# HFD: Higuchi Fractal Dimension\n",
    "# SVD_Entropy: SVD Entropy\n",
    "# Fisher_Information: Fisher Information\n",
    "# PFD: Petrosian Fractal Dimension\n",
    "# Spectral_Entropy: Spectral Entropy (Shannon's entropy of RIRs\n",
    "# detailed explanation: https://www.hindawi.com/journals/cin/2011/406391/\n",
    "def create_features(data):\n",
    "    Kmax = 5\n",
    "    Tau = 4\n",
    "    DE = 10\n",
    "    Band = np.arange(1,86)\n",
    "    Fs = 173\n",
    "    F = np.zeros((data.shape[0],6))\n",
    "    for i in range(data.shape[0]): # loop through the rows of raw data\n",
    "        mat = data[i][:]\n",
    "        DFA                = pyeeg.dfa(mat)\n",
    "        HFD                = pyeeg.hfd(mat,Kmax)\n",
    "        SVD_Entropy        = pyeeg.svd_entropy(mat,Tau,DE)\n",
    "        Fisher_Information = pyeeg.fisher_info(mat,Tau,DE)\n",
    "        PFD                = pyeeg.pfd(mat)\n",
    "        Spectral_Entropy   = pyeeg.spectral_entropy(mat, Band, Fs, Power_Ratio=None)\n",
    "        F[i][:] = [DFA, HFD, SVD_Entropy, Fisher_Information, PFD, Spectral_Entropy]\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Dataset:\n",
      "X_train: (225, 6) X_test (75, 6)\n",
      "-------------------------------------------------\n",
      "[0.8533333333333334, 'Nearest Neighbors']\n",
      "[0.25333333333333335, 'Linear SVM']\n",
      "[0.84, 'RBF SVM']\n",
      "[0.8933333333333333, 'Gaussian Process']\n",
      "[0.88, 'Decision Tree']\n",
      "[0.8666666666666667, 'Random Forest']\n",
      "[0.6533333333333333, 'Neural Net']\n",
      "[0.84, 'AdaBoost']\n",
      "[0.7333333333333333, 'Naive Bayes']\n",
      "[0.8, 'QDA']\n"
     ]
    }
   ],
   "source": [
    "# Load data and labels from files\n",
    "data, labels = load_data()\n",
    "# Calculate features from raw data\n",
    "features = create_features(data)\n",
    "# Split the dataset into training set and test set. The training set contains 4/5\n",
    "# of the entire dataset. The test set contains the rest of the 1/5.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "# Print the size of training and test dataset\n",
    "print('-------------------------------------------------')\n",
    "print('Dataset:')\n",
    "print('X_train:', X_train.shape, 'X_test', X_test.shape)\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# Import some models from sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import warnings\n",
    "\n",
    "# Classifiers we try\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "clf_score=[]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # ignore a warning message of sklearn\n",
    "    for name, clf in zip(names, classifiers): # loop through classifiers\n",
    "        clf.fit(X_train, y_train) # train a classifier\n",
    "        score = clf.score(X_test, y_test) # evaluate the accuracy\n",
    "        clf_score.append([score,name])\n",
    "\n",
    "for score in clf_score:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
